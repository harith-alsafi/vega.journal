\documentclass{ieeeaccess}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithm,algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{bm}
\usepackage{float}
\usepackage{dblfloatfix}
\makeatletter
\AtBeginDocument{\DeclareMathVersion{bold}
    \SetSymbolFont{operators}{bold}{T1}{times}{b}{n}
    \SetSymbolFont{NewLetters}{bold}{T1}{times}{b}{it}
    \SetMathAlphabet{\mathrm}{bold}{T1}{times}{b}{n}
    \SetMathAlphabet{\mathit}{bold}{T1}{times}{b}{it}
    \SetMathAlphabet{\mathbf}{bold}{T1}{times}{b}{n}
    \SetMathAlphabet{\mathtt}{bold}{OT1}{pcr}{b}{n}
    \SetSymbolFont{symbols}{bold}{OMS}{cmsy}{b}{n}
    \renewcommand\boldmath{\@nomath\boldmath\mathversion{bold}}}
\makeatother

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

%Your document starts from here ___________________________________________________
\begin{document}
\history{Date of publication xxxx 00, 0000, date of current version xxxx 00,
    0000.}
\doi{10.1109/ACCESS.2024.0429000}

\title{Vega: LLM-driven Intelligent Chatbot Platform for Internet of Things Development}
% //TODO: ask about IEEE membership
\author{\uppercase{Harith Al-Safi}, \IEEEmembership{Fellow, IEEE},
    \uppercase{Harith Ibrahim}, and Paul Steenson,
    \IEEEmembership{SeniroMember, IEEE}}

\address{School of Electronics and Electrical Engineering, University of Leeds,
    Leeds LS2 9JT, U.K}
\tfootnote{This paragraph of the first footnote will contain support
    information, including sponsor and financial support acknowledgment. For
    example, ``This work was supported in part by the U.S. Department of
    Commerce under Grant BS123456.''}

\markboth
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}
{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}

\corresp{Corresponding author: Harith Al-Safi (e-mail:
    harith.alsafi@gmail.com).}

% TODO: make verbs past tense
% alternative word to 'non-technical' users
% use Vega in abstract 
\begin{abstract}
    Large language models (LLMs) have revolutionized natural language
    processing, yet their potential in Internet of Things (IoT) and embedded systems (ESys) applications remains largely untapped. Traditional IoT interfaces often require specialized
    knowledge, creating barriers for non-technical users. We present a modular
    system that leverages LLMs to enable intuitive, natural language control of IoT
    devices, specifically a Raspberry Pi (RPi) connected to various sensors and
    devices. Our solution comprises three key components: a physical circuit with
    input and output devices, an RPi integrating a control server, and a web
    application integrating LLM logic. Users interact with the system through
    natural language commands, which the LLM interprets to call appropriate
    commands for the RPi. The RPi executes these instructions on the connected
    circuit, with outcomes communicated back to the user via LLM-generated
    responses. We empirically evaluate our system's performance across a range of
    task complexities and user scenarios, demonstrating its ability to handle
    complex, conditional logic without additional RPi-level coding. Our findings
    reveal that LLM-driven IoT control can effectively bridge the gap between
    complex device functionality and user-friendly interaction. We discuss the
    system's scalability, exploring its potential applications in diverse settings
    such as smart homes, industrial monitoring, and educational environments. By
    enabling natural language interaction with IoT devices, our approach not only
    enhances accessibility for non-technical users but also opens new avenues for
    creative and intelligent IoT applications. This research contributes to the
    growing body of work on interactive intelligent systems for IoT, offering
    insights into the design and implementation of LLM-integrated IoT interfaces.
\end{abstract}

\begin{keywords}
    Enter key words or phrases in alphabetical
    order, separated by commas. Autocorrelation, beamforming, communications
    technology, dictionary learning, feedback, fMRI, mmWave, multipath, system
    design, multipath, slight fault, underlubrication fault.
\end{keywords}

\titlepgskip=-21pt

\maketitle

\section{Introduction}
\label{sec:introduction}

Large language models (LLMs) have revolutionized natural language processing, demonstrating unprecedented capabilities in understanding and generating human-like text \cite{10.1145/3641289}. However, their potential in Internet of Things (IoT) and embedded systems (ESys) applications remains largely untapped. IoT systems have become increasingly prevalent across various domains, from smart homes to industrial automation \cite{8355897}. Despite their widespread adoption, developing and interacting with adaptive IoT systems often requires specialized knowledge and programming skills, creating significant barriers for non-technical users \cite{10.1145/3447526.3472036}.

Traditional IoT interfaces typically rely on graphical user interfaces (GUIs) or specific programming languages, which can be challenging for users without technical expertise \cite{10.1145/3447526.3472036}. This limitation hinders the widespread adoption and utilization of IoT technologies, particularly in scenarios where rapid deployment and intuitive interaction are crucial. While research has been conducted on natural language interfaces for IoT, the application of advanced language models to IoT control and interaction remains an underexplored area \cite{KASSAB2020102663}.

To address these challenges, we propose Vega, an intelligent chatbot platform that leverages LLMs to enable intuitive, natural language control of IoT devices. Our system focuses on a Raspberry Pi (RPi) connected to various sensors and devices as a representative IoT setup. By integrating LLMs with IoT infrastructure, we aim to bridge the gap between complex device functionality and user-friendly interaction, allowing users to control and query IoT systems using everyday language.

Our research builds upon recent advancements in LLMs, specifically OpenAI's GPT-based models \cite{OpenAI_GPT}, which utilize transformer neural network architectures to capture context and relationships within text data. By applying these powerful language understanding capabilities to IoT interaction, we aim to create a more accessible and flexible approach to device control and monitoring. Our approach not only enhances accessibility for non-technical users but also opens new avenues for creative and intelligent IoT applications, addressing the standardization challenges highlighted by Al-Qaseem \cite{7821686}.

Vega's architecture comprises three key components: a physical circuit with input and output devices, an RPi integrating a control server, and a web application incorporating LLM logic. This modular design allows for flexibility and scalability, enabling the system to adapt to various IoT scenarios and user requirements \cite{taylor2010software}. By utilizing the RPi as a central hub, we can leverage its versatility and widespread adoption in the IoT community \cite{8067944}.

The main contributions of this paper are as follows:

% //TODO: maybe mention the web app as one of the contributions 
\begin{enumerate}
    \item We present a modular architecture that integrates LLMs with IoT systems, specifically designed for natural language interaction with RPi-based setups.
    \item We develop a novel approach for translating natural language commands into executable instructions for IoT devices, capable of handling complex, conditional logic without additional RPi-level coding.
    \item We implement and evaluate a prototype system demonstrating the feasibility and effectiveness of LLM-driven IoT control across a range of task complexities and user scenarios.
    \item We provide insights into the scalability and potential applications of our approach in diverse settings such as smart homes, industrial monitoring, and educational environments.
\end{enumerate}

The rest of this paper is organized as follows: Section \ref{sec:background} provides background information and discusses related work in IoT interfaces and natural language processing. Section \ref{sec:methodology} details our methodology, including the overall system architecture, physical circuit design, RPi configuration, and web application implementation. Section \ref{sec:experiment} presents our experimental setup, results, and analysis, showcasing the system's performance in handling complex commands and its potential real-world applications. Finally, Section \ref{sec:conclusion} concludes the paper and outlines directions for future research.

\section{Background and Related Work}
\label{sec:background}

\subsection{Industrial applications of LLM's}
LLM's have revolutionized natural language processing, with the Transformer architecture \cite{DBLP:journals/corr/VaswaniSPUJGKP17} serving as a foundational breakthrough. These models, trained on vast corpora, have demonstrated remarkable versatility across diverse domains, including robotics and IoT applications. 

Maddiga et al. \cite{10121440} showcased this versatility with Chat2VIS, leveraging ChatGPT and GPT-3 to generate data visualizations from natural language queries. Their innovative approach demonstrated how LLM's could be effectively used to convert free-form natural language directly into visualization code, even when queries were highly misspecified or underspecified. Meanwhile, Gupta et al. \cite{10198233} explored the dual-edged implications of ChatGPT in cybersecurity, coining the term "ThreatGPT" to highlight potential risks. Their research delved into both the offensive and defensive applications of generative AI in cybersecurity. As they demonstrated how malicious actors could exploit ChatGPT's capabilities for creating social engineering attacks. They also examined how these same tools could be used to enhance cybersecurity measures, such as improving threat intelligence.

Recent research has explored the integration of LLMs with robotic systems, paving the way for intuitive human-robot interaction. Singh and Blukis \cite{Singh2023} introduced ProgPrompt, a novel approach leveraging LLMs to generate action sequences based on natural language instructions. By prompting LLMs with program-like specifications of available actions and objects, along with example programs, their method enables plan generation across diverse environments, robot capabilities, and tasks. This work demonstrated state-of-the-art success rates in VirtualHome household tasks and was successfully deployed on a physical robot arm for tabletop tasks.

Expanding on this concept, Driess et al. \cite{10.5555/3618408.3618748} proposed PaLM-E, an embodied multimodal language model that incorporates real-world sensor data into language models. PaLM-E is trained on tasks such as robotic manipulation planning and visual question answering, exhibiting positive transfer across language, vision, and visual-language domains. This research highlights the potential of LLMs in grounding language understanding in physical environments, a crucial aspect for IoT applications.

In the context of multi-agent systems, Kannan et al. \cite{kannan2024smartllmsmartmultiagentrobot} developed SMART-LLM, a framework for embodied multi-robot task planning. This approach uses LLMs to convert high-level task instructions into multi-robot task plans through a series of stages, including task decomposition, coalition formation, and task allocation. The authors created a benchmark dataset for validating multi-robot task planning problems, demonstrating the framework's effectiveness in both simulated and real-world scenarios.

Wu et al. \cite{Wu2023} presented TidyBot, a system that combines language-based planning and perception with LLMs to infer generalized user preferences for household cleanup tasks. This research demonstrates the potential of LLMs in personalizing robot assistance, achieving 91.2\% accuracy on unseen objects in their benchmark dataset and successfully putting away 85.0\% of objects in real-world test scenarios.

While these advancements primarily focus on robotics, they lay a solid foundation for extending similar techniques to IoT scenarios. The ability to interpret natural language instructions, generate action sequences, and integrate multimodal sensor data holds significant potential for enabling intuitive and intelligent control of IoT devices and systems. As research progresses, we anticipate further innovations in LLM-driven IoT interfaces, potentially revolutionizing how users interact with smart environments.
% -----------------------------------------------------------------------------------------

% \\ TODO: refine this section a bit more 
\subsection{Natural Language Processing for IoT}
Natural Language Processing (NLP) has emerged as a transformative technology in IoT applications, enabling intuitive human-machine interactions. The integration of NLP in IoT systems allows users to control and query devices using everyday language, bridging the gap between complex technological interfaces and user-friendly experiences \cite{10.1145/3643505}. This integration is particularly crucial as IoT devices become ubiquitous in various domains, from smart homes to industrial settings, where ease of use and accessibility are paramount.

Recent research has demonstrated the potential of NLP in IoT contexts. For instance, Petrović et al. explored the use of ChatGPT in IoT systems, focusing on Arduino-based applications \cite{10315791}. Their work highlighted the possibilities of leveraging LLMs for both question-answering and automated code generation in IoT environments. Similarly, Zhong et al. proposed CASIT, a collective intelligent agent system for IoT that utilizes LLMs to process and interpret data from multiple sources efficiently \cite{10439991}. These studies underscore the growing interest in applying advanced NLP techniques to enhance IoT functionality and user experience.

The integration of LLMs represents a significant advancement in NLP capabilities for IoT. Traditional NLP methods often struggle with context understanding and complex query interpretation, limitations that LLMs can overcome. LLMs offer improved natural language understanding, enabling more nuanced and context-aware interactions with IoT devices. For example, King et al. demonstrated how LLMs can interpret under-specified commands in smart home environments, translating vague user intentions into specific device actions \cite{10.1145/3643505}.

The potential of LLMs in IoT extends beyond simple command interpretation. They can enable more sophisticated applications such as predictive maintenance, anomaly detection, and personalized user experiences. Sarzaeim et al. explored the use of LLMs in smart policing systems, showcasing their potential in complex data analysis and pattern recognition \cite{10538107}. This application hints at the broader possibilities of LLMs in IoT, where they could be used to analyze and interpret vast amounts of sensor data, making IoT systems more intelligent and proactive.

However, integrating LLMs into IoT systems also presents challenges, including privacy concerns, computational requirements, and the need for domain-specific training. Despite these challenges, the potential benefits of LLM-enhanced NLP in IoT are significant. As demonstrated by Xu et al., natural language interfaces can greatly improve the usability of IoT platforms, allowing for more complex and nuanced interactions \cite{9808139}. By leveraging the advanced capabilities of LLMs, future IoT systems could offer unprecedented levels of intuitive control and intelligent automation, paving the way for more accessible and powerful IoT applications across various domains.

% // TODO: target this section a bit more to what we are doing 
\subsection{Chat oriented architectures}
% The integration of large language models (LLMs) with Internet of Things (IoT) systems has emerged as a promising frontier, enabling natural language interaction and intelligent control of physical devices. While this specific application domain remains relatively unexplored, several recent works have pioneered the fusion of LLMs and robotics, laying the groundwork for their extension to IoT scenarios \cite{10.1145/3610977.3634966}.

Chatbots have gained significant traction across various industries, serving as direct communication channels between companies and end-users \cite{8960373}. However, existing frameworks often require advanced technical knowledge for complex interactions and lack flexibility in adapting to evolving company needs. The deployment of chatbot applications typically demands a deep understanding of targeted platforms, particularly back-end connections, which increases development and maintenance costs \cite{8960373}.

To address these challenges, researchers have proposed novel approaches to chatbot development. Xatkit, for instance, offers a set of Domain Specific Languages to define chatbots in a platform-independent manner, along with a runtime engine for automatic deployment and conversation management \cite{8960373}. Similarly, SPADE 3 presents a redesigned middleware to support the new generation of multi-agent systems, aiming to popularize agent technology as a dynamic and flexible solution to current problems \cite{9207929}.

Recent studies have explored multi-modal chatbots in intelligent manufacturing settings, demonstrating the potential for AI-powered dialogue systems to assist users in complex assembly tasks \cite{9440470}. These systems leverage both textual and visual features to improve intent classification and provide relevant information to users. The development of conversation-driven approaches for chatbot management has also shown promise in evolving chatbot content through the analysis of user interactions, allowing for a cyclic and human-supervised process \cite{9681834}.

In the realm of human-robot interaction, researchers have developed task-oriented dialogue systems for industrial robots, addressing the lack of domain-specific discourse corpora and emphasizing user experience alongside task completion rates \cite{9869659}. These efforts have resulted in datasets like IRWoZ and frameworks such as ToD4IR, which integrate small talk concepts and human-to-human conversation strategies to support more natural and adaptable dialogue environments.

The potential of LLMs in easing chatbot development has been demonstrated through large-scale models that can learn blended conversational skills when provided with appropriate training data and generation strategies \cite{roller-etal-2021-recipes}. These models have shown improvements in multi-turn dialogue engagingness and humanness measurements, paving the way for more sophisticated chatbot applications in various domains, including IoT systems. 

\Figure[t!](topskip=0pt, botskip=0pt, midskip=0pt)[width=\textwidth]{{figures/fig1-ab.png}}
{ \textbf{Overall architecture of Vega alongside a simple example.}\label{fig1}}
\section{Methodology}
\label{sec:methodology}
\subsection{Overall Architecture}


The architecture of the Vega system follows key principles of software design to ensure scalability, maintainability, and robustness \cite{taylor2010software}. The system adopts a modular approach, dividing functionality into distinct components with specific purposes. This design promotes code reuse, facilitates testing, and enhances overall maintenance. The architecture also implements separation of concerns, where different aspects such as user interface, core functionality, and data management are segregated into distinct layers, improving code organization and enabling independent development.

As shown in Figure \ref{fig1} (a), Vega's architecture comprises three main modules: a Web Application, a RPi, and a Physical Circuit. These modules interact in a client-server model \cite{tanenbaum2002distributed}, with the Web Application serving as the client and the RPi as the server. The Physical Circuit is connected to the RPi via hardwired connections.

The Web Application consists of two primary sub-modules: the User Interface (VegaChat) and the App Logic (VegaAi). The App Logic incorporates LLM logic for translating user input into commands and generating responses. Redis \cite{6106531} is employed as a non-relational database to store chat history, messages, and RPi connection states.

The RPi module hosts a Control Server (VegaPi) responsible for parsing requests from the App Logic and executing them on the Physical Circuit. An SQLite database \cite{sqlite, sqliteapplication} is used to store data extracted from the physical circuit. The Physical Circuit comprises input devices (sensors) and output devices (LEDs, LCDs, etc.) connected to the RPi's General Purpose Input/Output (GPIO) pins.

A typical use case shown in Figure  \ref{fig1} (b) involves a user interacting with the Web Application interface, sending a natural language command such as "Turn on the red LED." The LLM interprets this command and sends the appropriate instruction to the RPi's Control Server. The server then relays the command to the Physical Circuit via GPIO pins. Upon execution, the circuit sends feedback to the RPi, which is then communicated back to the user through the Web Application.

% // TODO: be consistent with what you use LLM or GPT and define we are using Open AI from the start
The technology stack for Vega has been carefully selected to ensure robustness, scalability, and accessibility \cite{math9040308}. The Web Application is built using React \cite{React2024} with TypeScript, employing RadixUI \cite{radix-ui} for accessible components and TailwindCSS \cite{tailwindcss} for responsive design. The App Logic utilizes Node.js and integrates with OpenAI's GPT models \cite{OpenAI_GPT} for natural language processing. The RPi Control Server is developed using Flask \cite{Flask2024}, a lightweight Python web framework, while the circuit code leverages the RPi library for GPIO interaction.

% // TODO: this paragraph seems to be repeated a lot
This architecture enables Vega to bridge the gap between complex IoT functionality and user-friendly interaction. By leveraging LLMs for natural language processing and control, the system opens up new possibilities for intuitive IoT applications in various domains, from smart homes to industrial monitoring and educational environments \cite{8067944}. The modular design and carefully chosen technology stack ensure that Vega remains adaptable, maintainable, and scalable as IoT applications continue to evolve and expand.

\subsection{Physical Circuit Design}

\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[width=\textwidth]{{figures/fig5.png}}
{ \textbf{Soldered physical circuit connected to the RPi}\label{fig2}}

The physical implementation of the Vega platform comprises a custom-designed circuit board that interfaces with the RPi, integrating various input and output devices to facilitate IoT and embedded systems applications. This hardware configuration forms the foundation for the natural language-controlled system, enabling users to interact with physical components through LLM-interpreted commands.

As shown in Figure \ref{fig2}, the circuit board incorporates a diverse array of input devices, including an ultrasonic sensor for distance measurement, a limit switch for binary state detection, a temperature and humidity sensor for environmental monitoring, a GPS module for location tracking, and a push button for direct user input \cite{electronicwings_sensors_modules}. These components collectively provide a rich set of data sources, enabling the system to respond to complex, context-aware queries and commands.

% // TODO: unnessesary yap
Output devices on the board include a 12V fan for cooling or air circulation, multiple LEDs (yellow, red, and blue) for visual indicators, a 5V servo motor for precise rotational control, and an I2C LCD display for text output. A 5V relay is incorporated to control the 12V fan, demonstrating the system's capability to manage higher-voltage components safely \cite{smith2020}. The inclusion of these diverse output devices allows for a wide range of physical responses to user commands, from simple visual feedback to more complex mechanical actions.

% // TODO: unnessesary yap
Power management is a crucial aspect of the circuit design. While most components operate on the 5V supply provided by the RPi, the 12V fan requires a separate power source. To address this, a 9V battery is utilized in conjunction with the relay, ensuring proper voltage supply while maintaining RPi-based control \cite{monk2019}. This setup illustrates the system's ability to accommodate components with varying power requirements within a unified control structure.

The circuit board is designed to connect directly to the RPi's GPIO pins, streamlining the interface between the physical components and the computational core of the system. A camera module, while not physically present on the circuit board, is connected directly to the RPi, expanding the system's capabilities to include image capture and analysis \cite{pi_camera_2018}.

This hardware configuration supports a wide range of potential applications. In smart home scenarios, the temperature sensor and fan could be used for automated climate control, while the GPS module could enable location-based automation in mobile or outdoor settings. In industrial environments, the ultrasonic sensor and limit switch could be employed for proximity detection and safety systems, with the LEDs and LCD providing status information to operators \cite{mcmanus2021}.

% // TODO: this paragraph seems to be repeated a lot
The versatility of this hardware setup, combined with the LLM-driven control system, enables the exploration of complex, conditional logic without requiring additional RPi-level coding. This integration of diverse sensors and actuators with natural language processing capabilities represents a significant step forward in creating intuitive, user-friendly interfaces for IoT and embedded systems, bridging the gap between sophisticated device functionality and accessible user interaction.

\subsection{Raspberry Pi Design}

\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[scale=0.4]{{figures/fig6.png}}
{ \textbf{Architecture design of the RPi control server}\label{fig3}}

The architecture of the RPi integration with the existing codebase is designed to enable seamless control and manipulation of the circuit without interfering with pre-existing logic. This approach leverages parallel computing concepts, utilizing processor cores and threads to execute specific logic concurrently with existing code \cite{wilkinson2005parallel}.

The system architecture, illustrated in Figure  \ref{fig3}, comprises two main threads: the Control Server Thread and the Database Thread. The Control Server Thread manages a Flask-based web framework, storing predefined functions for a set of circuit devices. These functions are exposed through a REST API, facilitating communication between different software systems over the internet \cite{Surwase2016RESTAM}.

The Database Thread retrieves sensor data at two-second intervals, storing it in an SQLite database. This persistent storage solution ensures data preservation in the event of system failures, enabling data recovery, analytics, and statistical analysis. The stored data can be retrieved upon request and provided to the LLMs in the web application, enhancing system monitoring and diagnostic capabilities.

\begin{table}
    \caption{\textbf{Physical devices defined on the Control Server, which are then supplied to the LLM}}
    \label{table1}
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{|p{30pt}|p{25pt}|p{180pt}|}
        \hline
        \textbf{Symbol} &
        \textbf{Type}   &
        \textbf{Description}                                             \\
        \hline
        ULTS   &
        Input  &
        Ultrasonic Distance Sensor in 'cm'                      \\
        \hline
        CAM    &
        Input  &
        Camera device for picture input                         \\
        \hline
        GPS    &
        Input  &
        GPS device for longitude and latitude coordinates       \\
        \hline
        TMP    &
        Input  &
        Temperature sensor giving response in degree celcuis    \\
        \hline
        FAN    &
        Output &
        12V fan controled by a digital GPIO pin through a relay \\
        \hline
        LCD    &
        Output &
        I2C LCD for displaying strings                          \\
        \hline
        SRV    &
        Output &
        Servo motor rotates using PWM to a given angles         \\
        \hline
        LED1   &
        Output &
        Yellow LED light                                        \\
        \hline
        LED2   &
        Output &
        Red LED light                                           \\
        \hline
        LED3   &
        Output &
        Blue LED light                                          \\
        \hline
    \end{tabular}
\end{table}

Table \ref{table1} presents the devices defined in the Control Server, categorized as inputs or outputs. This information is stored and transmitted in JSON format via the "get-devices" REST API endpoint. Input devices primarily transmit data for database storage, while output devices receive commands for circuit manipulation.

\begin{table}
    \caption{\textbf{Defined functions on the Control Server, called by the LLM based on user input, executes on the RPi and processed on the webapp}}
    \label{table2}
    \setlength{\tabcolsep}{3pt}
    \begin{tabular}{|p{80pt}|p{70pt}|p{85pt}|}
        \hline
        \textbf{Function}    &
        \textbf{Description} &
        \textbf{Use Case} \\
        \hline
        set\underbar{ }led   &
        Toggles specefic LED &
        "Turn on yellow LED" \\
        \hline 
        set\underbar{ }fan   &
        Toggles fan on or off&
        "Turn on the fan" \\
        \hline
        get\underbar{ }recorded\underbar{ }sensor\underbar{ }data   &
        Gets interval sensor data from database&
        "Plot me the distance data in last 30 seconds" \\
        \hline
        get\underbar{ }raspberry\underbar{ }stats   &
        Gets CPU, RAM, Disk of RPi&
        "What is the currrent disk usage" \\
        \hline
        capture\underbar{ }image&
        Capture and upload image to Imgur&
        "Capture an image, does it contain a pen?" \\
        \hline
        get\underbar{ }connected\underbar{ }devices    &
        Fetches the data of connected devices&
        "What is the current humidity and temperature" \\
        \hline
        get\underbar{ }location\underbar{ }   &
        Gets the current  \newline
        location from GPS&
        "From the location are we currently in Leeds?" \\
        \hline
        set\underbar{ }servo\underbar{ }angles    &
        Turn servo to certain angle &
        "Turn the servo to 10 then 180 degrees" \\
        \hline
    \end{tabular}
\end{table}
\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[width=\textwidth]{{figures/fig9.png}}
{ \textbf{Webapp user interface implementation}\label{fig4}}
% // TODO: mention how this is a great alternative to code generation 
The Control Server exposes a set of defined functions, listed in Table \ref{table2}, which the LLM utilizes to determine logic and execute commands on circuit components. These functions are accessible to the LLM through the "get-functions" REST API endpoint. To execute a particular function, the LLM passes the function identifier and required parameters to the web application logic, which then invokes the "run-function" API endpoint. 



The choice of REST API over alternative protocols such as MQTT was based on several factors. REST offers simplicity, scalability, and statelessness, making it well-suited for web-based applications \cite{s21206904}. It also provides a uniform interface, enabling easier integration with various client applications. While MQTT excels in low-bandwidth, high-latency environments, the current system architecture prioritizes the flexibility and widespread support offered by REST APIs in web development ecosystems.

% \Figure[t!](topskip=0pt, botskip=0pt,
% midskip=0pt)[scale=0.17]{{figures/fig11-refined.png}}
% { \textbf{Webapp user interface implementation}\label{fig4}}

The communication flow between the web application and the RPi follows a request-response pattern. The web application sends REST API requests with JSON data specifying the function and arguments for the RPi to execute. The RPi processes these requests, executes the specified functions, and returns JSON responses with the execution status to the web application. This bidirectional communication enables real-time control and monitoring of the IoT devices.

% // TODO: this paragraph seems to be repeated a lot
This architecture facilitates a modular and extensible system, allowing for easy addition of new devices and functions. It also provides a layer of abstraction between the physical hardware and the LLM-driven interface, enabling natural language control of IoT devices without requiring users to understand the underlying technical details. The integration of LLMs with this IoT control system represents a significant step towards more intuitive and accessible IoT interfaces, potentially broadening the application of IoT technologies across various domains \cite{taylor2010software}.

\subsection{Web App User Interface}

% // TODO: is this clear enough?
The web application forms the core of the Vega platform, initiating all LLM processing and circuit manipulation tasks. Its architecture is modular, separating the User Interface (VegaChat) from the App Logic (VegaAi). The User Interface shown in Figure \ref{fig4} comprises a Top Bar with RPi connection management and configuration options, and a Chat UI displaying LLM responses and user messages. A Chat History UI manages previous interactions. The App Logic includes Data Management, RPi Bridge, and LLM Agents components, handling data entities, RPi communication, and LLM processing respectively.

\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[width=\textwidth]{{figures/fig13-refined.png}}
{ \textbf{Webapp logic design}\label{fig5}}


% // TODO: Maybe expand a bit more
The UI design prioritizes usability, drawing inspiration from established chatbot interfaces \cite{OpenAI_GPT}. It features a sidebar for chat history, a top bar for configurations, and a main chat area. An automated mode facilitates efficient testing for advanced users while maintaining simplicity for novices. The interface incorporates a Markdown renderer to appropriately display formatted text generated by the LLM.


The platform supports various data types and formats to enhance user interaction. It can display GPS data as maps, sensor readings as plots, and camera module output as images. Additionally, it visualizes LLM-generated plans as flow charts. This versatility allows the interface to accommodate diverse IoT devices and sensors, presenting their data in intuitive, visual formats.

% // TODO: Maybe expand a bit more
By leveraging OpenAI's API, the application accesses LLM capabilities without the substantial computational overhead of local hosting \cite{kim2024llmemestimatinggpumemory}. This design choice enhances the platform's accessibility and scalability, enabling its deployment across a wide range of devices and use cases in IoT and embedded systems development.


\subsection{Web App Logic}
The Application Logic component serves as the core operational engine of the Vega system, managing communication with the RPi Control Server and integrating LLM's for natural language processing and command interpretation. This component acts as a bridge between external elements, orchestrating the flow of information and translating user input into appropriate actions within the system architecture \cite{bass2003software}.

To establish a connection between the web application and the RPi, the user provides the IP address and port number of the RPi running the Control Server. The web application then initiates concurrent API calls to fetch circuit functions and device information from the Control Server. Upon receiving responses, the connection state is updated, synchronizing the "Raspi Devices" and "Raspi Functions" states which are fed to the LLM.

Figure 5 illustrates the system's workflow, demonstrating how user commands are processed through various stages involving LLM agents. When a user inputs a natural language command (e.g., "turn on red LED and capture image"), the system follows these steps:

\begin{enumerate}
    \item The LLM Planning Agent generates a flowchart visualizing the planned steps.
    \item The Stateless LLM Chat Agent processes the message and determines if a function call to the RPi is necessary.
    \item If required, the function is executed on the RPi, which returns a response.
    \item For image data, the Stateless LLM Image Agent analyzes and generates a description.
    \item Results are displayed on the web application's UI, providing feedback to the user.
\end{enumerate}

\Figure[b!](topskip=-10pt, botskip=0pt,
midskip=0pt)[width=0.99\columnwidth]{{figures/fig12.png}}
{ \textbf{Execution of the LLM Chat Agent}\label{fig6}}

\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[width=\textwidth]{{figures/fig30.png}}
{ \textbf{System case studies}\label{fig7}}


The system employs three main LLM agents: Chat, Planning, and Image. The LLM Chat Agent, as depicted in Figure 6, operates in two scenarios. In a normal chat scenario, it processes user input and generates a textual response. In a function call scenario, it recognizes the need for a hardware action and outputs a JSON-formatted function call for the RPi.

This approach of using LLM agents for command interpretation and execution offers several advantages over traditional code generation methods. It enhances scalability and adaptability, allowing for easy integration of new sensors and data types without significant system modifications \cite{yang2023autogptonlinedecisionmaking}. Additionally, it improves system security by limiting direct code execution on the RPi, instead relying on predefined functions interpreted by the LLM.

% The modular design of the system facilitates the incorporation of additional agents, such as those handling voice or video input, extending the system's capabilities to encompass audio and visual recognition functionalities. This flexibility allows for future expansions without major architectural changes.

% The App Logic module ensures that changes are rendered directly onto the User Interface, maintaining a consistent global state represented by the "Message History." This state is continuously supplied to the LLM during each execution cycle, enabling it to make informed decisions based on the system's current status and previous interactions.

% By leveraging LLMs for IoT control, Vega bridges the gap between complex device functionality and user-friendly interaction. This approach not only enhances accessibility for non-technical users but also opens new avenues for creative and intelligent IoT applications in diverse settings such as smart homes, industrial monitoring, and educational environments.






\section{Experiment and Results}
\label{sec:experiment}


\subsection{Complex Commands In Action}



\subsection{Automated Evaluation}
\Figure[t!](topskip=0pt, botskip=0pt, midskip=0pt)[width=0.99\columnwidth]{{figures/fig15-refined.png}}
{ \textbf{Magnetization as a function of applied field.
It is good practice to explain the significance of the figure in the caption.}\label{fig6}}
\subsection{Result Analysis}

% define how complexity is measured 
\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[width=0.99\columnwidth]{{figures/fig17.png}}
{ \textbf{Evaluation metrics for the functions defined earlier in .}\label{fig7}}

\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[width=0.99\columnwidth]{{figures/fig18.png}}
{ \textbf{Message complexity against the number of functions called per message.}\label{fig8}}

% change this to percentage
\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[width=0.99\columnwidth]{{figures/fig19.png}}
{ \textbf{Message complexity against all evaluation metrics and most importantly the success rate.}\label{fig9}}


% \Figure[t!](topskip=0pt, botskip=0pt,
% midskip=0pt)[width=0.99\columnwidth]{{figures/fig26.png}}
% { \textbf{Magnetization as a function of applied field.
%         It is good practice to explain the significance of the figure in the
%         caption.}\label{fig9}}

% change the temperature its wrong
\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[width=0.99\columnwidth]{{figures/fig36.png}}
{ \textbf{Success rate against message complexity and temperature of the LLM.}\label{fig10}}

\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[width=0.99\columnwidth]{{figures/fig37.png}}
{ \textbf{Success rate against message complexity and Top P of the LLM.}\label{fig11}}

\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[scale=0.42]{{figures/fig34.png}}
{ \textbf{What types of errors occured throughout testing.}\label{fig12}}

\Figure[t!](topskip=0pt, botskip=0pt,
midskip=0pt)[scale=0.38]{{figures/fig35.png}}
{ \textbf{Success rate of different tones of the same message.}\label{fig13}}

\subsection{Real Life Applicability}

\section{Conclusion and future work}
\label{sec:conclusion}

\section*{Acknowledgment}

\bibliographystyle{unsrt}
\bibliography{refs}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author1.png}}]{Harith Al-Safi} received the BEng industrial degree in Electronics and Computer Engineering from
%     the University of Leeds, Leeds, in 2024. From 2022 to 2023, he was an IoT Software Engineer at Johnson Controls. He is currently pursuing a Graduate Software Developer role at BT Group. His research interests include IoT, embedded systems, and machine learning.
% \end{IEEEbiography}

% \begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{author2.png}}]{Second
%         B. Author} (M'76--SM'81--F'87) and all authors may include
%     biographies. Biographies are often not included in conference-related
%     papers. This author became a Member (M) of IEEE in 1976, a Senior
%     Member (SM) in 1981, and a Fellow (F) in 1987. The first paragraph may
%     contain a place and/or date of birth (list place, then date). Next,
%     the author's educational background is listed. The degrees should be
%     listed with type of degree in what field, which institution, city,
%     state, and country, and year the degree was earned. The author's major
%     field of study should be lower-cased.

%     The second paragraph uses the pronoun of the person (he or she) and not the
%     author's last name. It lists military and work experience, including summer
%     and fellowship jobs. Job titles are capitalized. The current job must have
%     a
%     location; previous positions may be listed
%     without one. Information concerning previous publications may be included.
%     Try not to list more than three books or published articles. The format for
%     listing publishers of a book within the biography is: title of book
%     (publisher name, year) similar to a reference. Current and previous
%     research
%     interests end the paragraph.

%     The third paragraph begins with the author's
%     title and last name (e.g., Dr.\ Smith, Prof.\ Jones, Mr.\ Kajor, Ms.\
%     Hunter).
%     List any memberships in professional societies other than the IEEE.
%     Finally,
%     list any awards and work for IEEE committees and publications. If a
%     photograph is provided, it should be of good quality, and
%     professional-looking. Following are two examples of an author's biography.
% \end{IEEEbiography}

% \newpage

%If you do not have or do not want to include a photo, you can use IEEEbiographynophoto as shown below:

% \begin{IEEEbiographynophoto}{Third C. Author, Jr.} (M'87) received the B.S.
%     degree in mechanical
%     engineering from National Chung Cheng University, Chiayi, Taiwan, in 2004
%     and the M.S. degree in mechanical engineering from National Tsing Hua
%     University, Hsinchu, Taiwan, in 2006. He is currently pursuing the Ph.D.
%     degree in mechanical engineering at Texas A{\&}M University, College
%     Station, TX, USA.

%     From 2008 to 2009, he was a Research Assistant with the Institute of
%     Physics, Academia Sinica, Tapei, Taiwan. His research interest includes the
%     development of surface processing and biological/medical treatment
%     techniques using nonthermal atmospheric pressure plasmas, fundamental study
%     of plasma sources, and fabrication of micro- or nanostructured surfaces.

%     Mr. Author's awards and honors include the Frew Fellowship (Australian
%     Academy of Science), the I. I. Rabi Prize (APS), the European Frequency and
%     Time Forum Award, the Carl Zeiss Research Award, the William F. Meggers
%     Award and the Adolph Lomb Medal (OSA).
% \end{IEEEbiographynophoto}

\EOD

\end{document}
